{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb344640-36ad-4283-b75d-80d5f77c77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94eae8fd-e164-404e-b321-5bfe74bba1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic自动求导例子1\n",
    "# 创建张量\n",
    "x = torch.tensor(1.,requires_grad=True)\n",
    "w = torch.tensor(2.,requires_grad=True)\n",
    "b = torch.tensor(3.,requires_grad=True)\n",
    "\n",
    "# 计算图\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# 计算梯度\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce234e1-c68b-43bd-a7c2-6b0da8182915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x梯度：2.0,w梯度：1.0,b梯度：1.0。\n"
     ]
    }
   ],
   "source": [
    "print(f\"x梯度：{x.grad},w梯度：{w.grad},b梯度：{b.grad}。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4d60f8-1dfa-4aec-a869-b49c7154bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0161, -1.2447,  0.4456],\n",
       "         [ 0.6961,  0.0405, -1.0334],\n",
       "         [ 0.8368,  0.0649,  1.0216],\n",
       "         [ 0.3938,  0.2129,  0.4330],\n",
       "         [ 2.4811,  0.1600, -0.5196],\n",
       "         [ 0.7483, -1.4351,  0.4341],\n",
       "         [ 1.1426,  0.0049, -1.3054],\n",
       "         [-0.7675, -0.0376, -0.2953],\n",
       "         [-0.1043,  0.5747,  0.2419],\n",
       "         [ 0.9974, -1.1863,  1.2229]]),\n",
       " tensor([[-0.7404, -0.4340],\n",
       "         [-0.3005, -0.5322],\n",
       "         [ 0.4864,  0.7186],\n",
       "         [ 1.8049,  0.2626],\n",
       "         [ 1.0370,  0.1492],\n",
       "         [ 0.2374, -0.0412],\n",
       "         [ 0.9889,  0.6082],\n",
       "         [ 0.3513,  0.2129],\n",
       "         [-0.5119,  1.7907],\n",
       "         [ 0.2324, -0.3144]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic自动求导例子2\n",
    "# 创建张量\n",
    "x = torch.randn(10,3)\n",
    "y = torch.randn(10,2)\n",
    "\n",
    "x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b2604c-af7b-420f-b3ca-94736e87f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全连接层\n",
    "linear = nn.Linear(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a36cbe-0b12-44da-a9b1-b65ed0050276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1015, -0.4284, -0.2599],\n",
       "        [ 0.5061, -0.3982, -0.5315]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8189a6-093f-4d5d-b6de-68ea0f06b6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3696, -0.1182], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e43818-e06f-4f3a-823e-4f58b24619fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=2, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf30004b-bce5-4fba-90b9-1b38dbf5f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失和优化\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64cea269-a71e-46a2-9fcb-d1d9dfb6b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播\n",
    "output = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be82aa6-511c-4e92-8099-910fc35c5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算损失\n",
    "loss = criterion(output,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "454241f7-f162-4369-bc86-1daf89f752a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9240363836288452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd852566-e643-406a-913a-b87b9fe88eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反向传播\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf0052a-3b46-4136-a25e-cb949e548b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0368, -0.3487, -0.0012],\n",
       "        [ 0.5162, -0.3502, -0.3116]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89934126-0b13-4ce0-b067-b4141ea4f1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1815, 0.0447])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75999c62-9068-4a0a-9a13-0fa52a49fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "363103b9-ad92-45dc-80bb-60b37b80bcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1018, -0.4249, -0.2599],\n",
       "        [ 0.5010, -0.3947, -0.5284]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67839626-8bc5-4f25-9102-d6ec934fbdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3677, -0.1187], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1470f0ac-af15-4240-a375-964008ee87b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  0.9176262617111206\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6d81cb0-e3ae-4661-b04a-50311195202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array.\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "# Convert the numpy array to a torch tensor.\n",
    "y = torch.from_numpy(x)\n",
    "\n",
    "# Convert the torch tensor to a numpy array.\n",
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b6adb95-bfe5-4db9-b6a9-cb68b769dcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " array([[1, 2],\n",
       "        [3, 4]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c692e0-e268-4719-b9b3-21c276ea294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../../../data/',\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "\n",
    "image,label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99254dd1-96f9-48cc-841d-d4f3021272cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function Tensor.size>, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2759d87-b2b3-4884-9af3-43750c7ca1d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Mini-batch images and labels.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdata_iter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Actual usage of the data loader is as below.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Training code should be written here.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# When iteration starts, queue and thread start to load data from files.\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# Actual usage of the data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Training code should be written here.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69596e20-d0f3-4a36-8f40-c72ac2400353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should build your custom dataset as below.\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file paths or a list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0 \n",
    "\n",
    "# You can then use the prebuilt data loader. \n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "# ================================================================== #\n",
    "#                        6. Pretrained model                         #\n",
    "# ================================================================== #\n",
    "\n",
    "# Download and load the pretrained ResNet-18.\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# If you want to finetune only the top layer of the model, set as below.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
    "\n",
    "# Forward pass.\n",
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print (outputs.size())     # (64, 100)\n",
    "\n",
    "\n",
    "# ================================================================== #\n",
    "#                      7. Save and load the model                    #\n",
    "# ================================================================== #\n",
    "\n",
    "# Save and load the entire model.\n",
    "torch.save(resnet, 'model.ckpt')\n",
    "model = torch.load('model.ckpt')\n",
    "\n",
    "# Save and load only the model parameters (recommended).\n",
    "torch.save(resnet.state_dict(), 'params.ckpt')\n",
    "resnet.load_state_dict(torch.load('params.ckpt'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-tutorial",
   "language": "python",
   "name": "pytorch-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
